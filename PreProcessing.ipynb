{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PreProcessing",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "hnxZqoEg1YJZ",
        "colab_type": "code",
        "outputId": "84e43583-7856-4b79-a128-0d1034827e68",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        }
      },
      "source": [
        "#Mount the google drive for storing the data\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gUMKqWo81aB0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!ls \"/content/gdrive/My Drive\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sO_vftMn-90A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "os.chdir('gdrive/My Drive/traffic')  #change dir"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TZqAZ9gY1mKr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# !mkdir train  #create a directory named train/\n",
        "# !mkdir test  #create a directory named test/\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xDloR7Iz-3jK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# !unzip -q traffic-signs-preprocessed.zip -d train/  #unzip data in train/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GPMbESYS-jUC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!ls \"/content/gdrive/My Drive/traffic/train\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7O9bJehjesta",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Data downloaded from The German Traffic Sign Recognition Benchmark:\n",
        "# http://benchmark.ini.rub.de/?section=gtsrb&subsection=news"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DtkGu9vY1qN6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rEniEUJV2QjC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "cwd = os.getcwd()\n",
        "cwd\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bAuSN3Uy1vtd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "import pickle\n",
        "from PIL import Image\n",
        "from skimage.transform import resize\n",
        "from pylab import text\n",
        "import csv"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lkhGOvCS1yyI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Get names of every label class saved in a csv file. We have a total of 43 traffic sign labels.\n",
        "def label_name(file):\n",
        "    label_list = []\n",
        "    with open(file, 'r') as f:\n",
        "        reader = csv.reader(f)\n",
        "        for row in reader:\n",
        "            label_list.append(row[1])\n",
        "        del label_list[0]\n",
        "    return label_list"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "74C1IM1O12pH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Getting the data stored in pickle files. \n",
        "#The data is stored in dictionaries consisting of 4 keys: features, labels, sizes and coords.\n",
        "def get_rgb_data(file):\n",
        "    # Opening 'pickle' file and getting images\n",
        "    with open(file, 'rb') as f: \n",
        "        d = pickle.load(f, encoding='latin1')\n",
        "        x,y,s,c = d['features'].astype(np.float32), d['labels'], d['sizes'], d['coords'] \n",
        "    return x, y, s, c"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4AEMDua_EGrS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Features is a 4D array consisting of number of examples for each traffic sign type, its width, height and number of channels.\n",
        "# Labels is a 1D array consisting of label id of the traffic sign image. There are total 43 traffic sign types and the label id matching is done \n",
        "# with the label names in label_names.csv\n",
        "# Sizes is a 2D array which has the width and height of the image.\n",
        "# Coords is a 2D array which denotes the bounding frame coordinates around the image,i.e.(x1,y1,x2,y2)."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1ccjZBNlEM7i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Convert loaded data from rgb format to grayscale.\n",
        "def rgb_to_gray_scale(x_data):\n",
        "    x_g = np.zeros((x_data.shape[0], 1, 32, 32))\n",
        "    x_g[:, 0, :, :] = x_data[:, 0, :, :] * 0.299 + x_data[:, 1, :, :] * 0.587 + x_data[:, 2, :, :] * 0.114\n",
        "    return x_g"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NaOkVGcx13qi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#We now define a function for getting a random image from the specified traffic sign label class.\n",
        "def get_random_image(x_train, y_train, y_number):\n",
        "    image_indexes = np.where(y_train == y_number)\n",
        "    random_index = np.random.randint(0, np.bincount(y_train)[y_number] - 1)\n",
        "    return x_train[image_indexes][random_index]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E_z1aXf115sM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#We define a function to rotate the image and also change the brightness of the rotated image\n",
        "#https://stackoverflow.com/questions/9041681/opencv-python-rotate-image-by-x-degrees-around-specific-point\n",
        "#https://opencv-python-tutroals.readthedocs.io/en/latest/py_tutorials/py_imgproc/py_colorspaces/py_colorspaces.html\n",
        "\n",
        "def change_brightness_and_rotation(image):\n",
        "    #Set angle rotation to 25\n",
        "    angle_range = 25\n",
        "    angle_rotation = np.random.uniform(angle_range) - angle_range / 2\n",
        "    rows, columns, channels = image.shape\n",
        "    affine_matrix = cv2.getRotationMatrix2D((columns / 2, rows / 2), angle_rotation, 1)\n",
        "    #Lets rotate the image\n",
        "    rotated_image = cv2.warpAffine(image, affine_matrix, (columns, rows))\n",
        "\n",
        "    # Lets first convert the rotated image from RGB to HSV for changing its brightness \n",
        "    image_hsv = cv2.cvtColor(rotated_image, cv2.COLOR_RGB2HSV)\n",
        "    # Assign random value for brightness change\n",
        "    random_brightness = 0.25 + np.random.uniform()\n",
        "    image_hsv[:, :, 2] = image_hsv[:, :, 2] * random_brightness\n",
        "    # Lets convert the changed image back to RGB\n",
        "    image_rgb = cv2.cvtColor(image_hsv, cv2.COLOR_HSV2RGB)\n",
        "    return image_rgb"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "334NCfJh17rG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Now we create a function for equalization of the training datasets\n",
        "\n",
        "def training_dataset_equalization(x_train, y_train):\n",
        "    number_of_examples_for_every_label = np.bincount(y_train)\n",
        "    number_of_labels = np.arange(len(number_of_examples_for_every_label))\n",
        "    for i in number_of_labels:\n",
        "        number_of_examples_to_add = int(np.mean(number_of_examples_for_every_label) * 2.5) - \\\n",
        "                                    number_of_examples_for_every_label[i]\n",
        "        # Create two arrays for storing the new images\n",
        "        x_temp = []\n",
        "        y_temp = []\n",
        "        for j in range(number_of_examples_to_add):\n",
        "            getting_random_image = get_random_image(x_train, y_train, i)\n",
        "            x_temp.append(change_brightness_and_rotation(getting_random_image))\n",
        "            y_temp.append(i)\n",
        "        x_train = np.append(x_train, np.array(x_temp), axis=0)\n",
        "        y_train = np.append(y_train, np.array(y_temp), axis=0)\n",
        "    return x_train, y_train"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "42buYwXg19A6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Creating a function for changing the contrast of the images by performing Local Histogram Equalization \n",
        "# on the given imageset. We use openCV libraries for doing this.\n",
        "#Ref: https://opencv-python-tutroals.readthedocs.io/en/latest/py_tutorials/py_imgproc/py_histograms/py_histogram_equalization/py_histogram_equalization.html\n",
        "def local_histogram_equalization(image):\n",
        "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(4, 4))\n",
        "    return clahe.apply(image)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N9ZVAZON1-Zu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Now we define the data preprocessing part, whenever new a dataset is introduced, it is preprocessed by applying \n",
        "# transformations on the datasets as per the parameters being input.\n",
        "from sklearn.utils import shuffle\n",
        "def data_preprocessing(d, shuffle=False, lhe=False, norm_255=False, mean_norm=False, std_norm=False,\n",
        "                    transpose=True, colour='rgb'):\n",
        "    #If shuffle is set to true, then shuffle the dataset to generate randomized data\n",
        "    if shuffle:\n",
        "        np.random.seed(0)\n",
        "        np.random.shuffle(d['x_train'])\n",
        "        np.random.seed(0)\n",
        "        np.random.shuffle(d['y_train'])\n",
        "        np.random.seed(0)\n",
        "        np.random.shuffle(d['x_test'])\n",
        "        np.random.seed(0)\n",
        "        np.random.shuffle(d['y_test'])\n",
        "        np.random.seed(0)\n",
        "        np.random.shuffle(d['x_validation'])\n",
        "        np.random.seed(0)\n",
        "        np.random.shuffle(d['y_validation'])\n",
        "\n",
        "    #If Local Histogram Equalization is is set to true, then apply Local Histogram Equalization on the data\n",
        "    if lhe:\n",
        "        d['x_train'] = list(map(local_histogram_equalization, d['x_train'][:, 0, :, :].astype(np.uint8)))\n",
        "        d['x_train'] = np.array(d['x_train'])\n",
        "        d['x_train'] = d['x_train'].reshape(d['x_train'].shape[0], 1, 32, 32)\n",
        "        d['x_train'] = d['x_train'].astype(np.float32)\n",
        "        d['x_test'] = list(map(local_histogram_equalization, d['x_test'][:, 0, :, :].astype(np.uint8)))\n",
        "        d['x_test'] = np.array(d['x_test'])\n",
        "        d['x_test'] = d['x_test'].reshape(d['x_test'].shape[0], 1, 32, 32)\n",
        "        d['x_test'] = d['x_test'].astype(np.float32)\n",
        "        d['x_validation'] = list(map(local_histogram_equalization, d['x_validation'][:, 0, :, :].astype(np.uint8)))\n",
        "        d['x_validation'] = np.array(d['x_validation'])\n",
        "        d['x_validation'] = d['x_validation'].reshape(d['x_validation'].shape[0], 1, 32, 32)\n",
        "        d['x_validation'] = d['x_validation'].astype(np.float32)\n",
        "\n",
        "    # If norm255 is is set to true, then we apply Normalization on the data by dividing by 255.0.\n",
        "    if norm_255:\n",
        "        d['x_train'] = d['x_train'].astype(np.float32) / 255.0\n",
        "        d['x_validation'] /= 255.0\n",
        "        d['x_test'] /= 255.0\n",
        "        mean_image = np.mean(d['x_train'], axis=0)  # numpy.ndarray (3, 32, 32)\n",
        "        dictionary = {'mean_image_' + colour: mean_image}\n",
        "        with open('mean_image_' + colour + '.pickle', 'wb') as f_mean_image:\n",
        "            pickle.dump(dictionary, f_mean_image)\n",
        "        #Now lets calculate the standard deviation from the training dataset along the rows by specifying 'axis=0'\n",
        "        std = np.std(d['x_train'], axis=0)  # numpy.ndarray (3, 32, 32)\n",
        "        dictionary = {'std_' + colour: std}\n",
        "        with open('std_' + colour + '.pickle', 'wb') as f_std:\n",
        "            pickle.dump(dictionary, f_std)\n",
        "\n",
        "    # By calculating the mean image, and subtracting it from the dataset, we now normalize the data.\n",
        "    if mean_norm:\n",
        "        with open('mean_image_' + colour + '.pickle', 'rb') as f:\n",
        "            mean_image = pickle.load(f, encoding='latin1')\n",
        "        d['x_train'] -= mean_image['mean_image_' + colour]\n",
        "        d['x_test'] -= mean_image['mean_image_' + colour]\n",
        "        d['x_validation'] -= mean_image['mean_image_' + colour]\n",
        "\n",
        "    # Applying Standard Normalization by dividing with the standard deviation\n",
        "    if std_norm:\n",
        "        with open('std_' + colour + '.pickle', 'rb') as f:\n",
        "            std = pickle.load(f, encoding='latin1')\n",
        "\n",
        "        d['x_train'] /= std['std_' + colour]\n",
        "        d['x_test'] /= std['std_' + colour]\n",
        "        d['x_validation'] /= std['std_' + colour]\n",
        "\n",
        "    if transpose:\n",
        "        # This will transpose every dataset to make the channels come first\n",
        "        d['x_train'] = d['x_train'].transpose(0, 3, 1, 2)\n",
        "        d['x_test'] = d['x_test'].transpose(0, 3, 1, 2)\n",
        "        d['x_validation'] = d['x_validation'].transpose(0, 3, 1, 2)\n",
        "\n",
        "    return d\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yvScLqxu2AqJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#I have loaded and preprocessed data for rgb and grayscale separately\n",
        "# Step 1 - rgb data --> starts here\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HdKNRz6-2EA0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Lets load rgb data from the original training, validation and testing datasets and getting label names from 'label_names.csv' file\n",
        "x_train, y_train, s_train, c_train = get_rgb_data('/content/gdrive/My Drive/traffic/train/train.pickle')\n",
        "x_validation, y_validation, s_validation, c_validation = get_rgb_data('/content/gdrive/My Drive/traffic/train/valid.pickle')\n",
        "x_test, y_test, s_test, c_test = get_rgb_data('/content/gdrive/My Drive/traffic/train/test.pickle')\n",
        "label_list = label_name('/content/gdrive/My Drive/traffic/train/label_names.csv')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zJrxRz3q3MPu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Lets implement equalization of training dataset. Equalization is done only for the training datasets.\n",
        "\n",
        "x_train, y_train = training_dataset_equalization(x_train.astype(np.uint8), y_train)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tWgClQSgonLq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Now lets store the equalized data from the previous step into a dictionary\n",
        "\n",
        "d_loaded = {'x_train': x_train, 'y_train': y_train,\n",
        "            'x_validation': x_validation, 'y_validation': y_validation,\n",
        "            'x_test': x_test, 'y_test': y_test,\n",
        "            'labels': label_list}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3RsHDz8s3VMc",
        "colab_type": "code",
        "outputId": "c44bb651-5278-49bb-a6b1-3844067e6613",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "# Now lets apply different preprocessing functions on each of the pickle files\n",
        "# Apply basic shuffling and transposing the images in data0.pickle. This data0.pickle file is then reused, transformed by \n",
        "# using different methods and stored in different pickle files.\n",
        "# We have to run this only once, as the data0 is shuffled and transposed just once, further operations are carried out \n",
        "# on this modified data.\n",
        "\n",
        "data0 = data_preprocessing(d_loaded, shuffle=True, transpose=True)\n",
        "print(data0['x_train'][0, 0, :, 0])\n",
        "#Saving loaded and preprocessed data into a 'pickle' file\n",
        "with open('/content/gdrive/My Drive/traffic/train/data0.pickle', 'wb') as f:\n",
        "    pickle.dump(data0, f)\n",
        "del data0"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[ 96  98  98  96  98 104 105 105 105 105 102  91  74  83  99  94 101 103\n",
            " 100  85  89  92  98  98  90  82  99  87  86  50  56  42]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BsxFhwqp6AZH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Hnvy6Dm782u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 'New_Pickle1' Generation: Loading 'data0.pickle' dataset and perform basic normalization and mean normalization on it.\n",
        "# Opening file for reading in binary mode\n",
        "with open('/content/gdrive/My Drive/traffic/train/data0.pickle', 'rb') as f:\n",
        "    d_0_1 = pickle.load(f, encoding='latin1')  # dictionary type\n",
        "data1 = data_preprocessing(d_0_1, shuffle=False, norm_255=True, mean_norm=True, transpose=False,\n",
        "                        colour='rgb')\n",
        "# Saving loaded and preprocessed data into 'pickle' file\n",
        "with open('/content/gdrive/My Drive/traffic/train/data1.pickle', 'wb') as f:\n",
        "    pickle.dump(data1, f)\n",
        "del d_0_1\n",
        "del data1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OKPXB5cP8Nex",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 'New_Pickle2' Generation: Loading 'data0.pickle' dataset and basic normalization, standard normalization and mean normalization on it.\n",
        "# Opening file for reading in binary mode\n",
        "with open('/content/gdrive/My Drive/traffic/train/data0.pickle', 'rb') as f:\n",
        "    d_0_2 = pickle.load(f, encoding='latin1')  # dictionary type\n",
        "data2 = data_preprocessing(d_0_2, shuffle=False, norm_255=True, mean_norm=True, std_norm=True,\n",
        "                        transpose=False, colour='rgb')\n",
        "# Saving loaded and preprocessed data into 'pickle' file\n",
        "with open('/content/gdrive/My Drive/traffic/train/data2.pickle', 'wb') as f:\n",
        "    pickle.dump(data2, f)\n",
        "del d_0_2\n",
        "del data2\n",
        "\n",
        "# Step 1 - rgb data --> ends here"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WJudpum49dZg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Step 2 - grayscale data --> starts here\n",
        "# Loading 'data0.pickle' rgb dataset and going further with it\n",
        "# Opening file for reading in binary mode\n",
        "with open('/content/gdrive/My Drive/traffic/train/data0.pickle', 'rb') as f:\n",
        "    data0 = pickle.load(f, encoding='latin1')  # dictionary type\n",
        "\n",
        "# Converting rgb data to grayscale for training dataset\n",
        "x_train = rgb_to_gray_scale(data0['x_train'])\n",
        "\n",
        "# Converting rgb data to grayscale for testing dataset\n",
        "x_test = rgb_to_gray_scale(data0['x_test'])\n",
        "\n",
        "# Converting rgb data to grayscale for validation dataset\n",
        "x_validation = rgb_to_gray_scale(data0['x_validation'])\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DKNLNjgVqktt",
        "colab_type": "code",
        "outputId": "1dc4f64f-fa4e-454d-daf3-ce9dce1e1c81",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 266
        }
      },
      "source": [
        "# Putting loaded grayscale data into the dictionary\n",
        "d_loaded_gray = {'x_train': x_train, 'y_train': data0['y_train'],\n",
        "                 'x_validation': x_validation, 'y_validation': data0['y_validation'],\n",
        "                 'x_test': x_test, 'y_test': data0['y_test'],\n",
        "                 'labels': data0['labels']}\n",
        "\n",
        "# Showing the image by using obtained array with only one channel\n",
        "plt.imshow(x_train[9000, 0, :, :].astype(np.uint8), cmap=plt.get_cmap('gray'))\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD5CAYAAADhukOtAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K-LIoA6G9hzv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Saving loaded and preprocessed grayscale data into 'data_gray.pickle' file\n",
        "with open('/content/gdrive/My Drive/traffic/train/data_gray.pickle', 'wb') as f:\n",
        "    pickle.dump(d_loaded_gray, f)\n",
        "# Releasing memory\n",
        "del d_loaded_gray"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5GZ43vm69keD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 'New_Pickle3' Generation: Loading 'data_gray.pickle' dataset and perform basic normalization, mean normalization \n",
        "# and Local histogram equalization on it.\n",
        "# Loading 'data_gray.pickle' dataset and going further with it\n",
        "# Opening file for reading in binary mode\n",
        "\n",
        "with open('/content/gdrive/My Drive/traffic/train/data_gray.pickle', 'rb') as f:\n",
        "    d_0_3 = pickle.load(f, encoding='latin1')  # dictionary type\n",
        "\n",
        "data3 = data_preprocessing(d_0_3, shuffle=False, lhe=True, norm_255=True, mean_norm=True, std_norm=True,\n",
        "                        transpose=False, colour='gray')\n",
        "# Saving loaded and preprocessed data into 'pickle' file\n",
        "with open('/content/gdrive/My Drive/traffic/train/data3.pickle', 'wb') as f:\n",
        "    pickle.dump(data3, f)\n",
        "# Releasing memory\n",
        "del d_0_3\n",
        "del data3\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lTC54GZgBnPw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Applying preprocessing\n",
        "# 'New_Pickle4' Generation: Loading 'data_gray.pickle' dataset and perform basic normalization, \n",
        "#standard normalization, mean normalization and Local histogram equalization on it.\n",
        "# Opening file for reading in binary mode\n",
        "\n",
        "with open('/content/gdrive/My Drive/traffic/train/data_gray.pickle', 'rb') as f:\n",
        "    d_0_4 = pickle.load(f, encoding='latin1')  # dictionary type\n",
        "\n",
        "data4 = data_preprocessing(d_0_4, shuffle=False, lhe=True, norm_255=True, mean_norm=True, std_norm=True,\n",
        "                        transpose=False, colour='gray')\n",
        "# Saving loaded and preprocessed data into 'pickle' file\n",
        "with open('/content/gdrive/My Drive/traffic/train/data4.pickle', 'wb') as f:\n",
        "    pickle.dump(data4, f)\n",
        "# Releasing memory\n",
        "del d_0_4\n",
        "del data4"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xkkE5f6NQvLR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Now we are done with pre processing the data with different transformations and have stored them in 4 different pickle files.\n",
        "# Two of them are in RGB format while two are in Grayscale. "
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}